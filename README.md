# Creditâ€‘Defaultâ€¯PredictionÂ ðŸ“ŠðŸ’³

End-to-end machine learning pipeline to predict loan defaults, including data cleaning, feature engineering, training of six models, and ranking via a dashboard.

| Stage           | Tech                       |
|-----------------|----------------------------|
| **Storage**     | PostgreSQLÂ 16 Â· Parquet    |
| **MLÂ &Â Tuning** | LightGBM Â· Optuna Â· MLflow |
| **VizÂ /Â UI**    | Streamlit Â· Plotly         |
| **Language**    | PythonÂ 3.12                |

---

##â€¯1â€‚ProjectÂ Overview
* **Dataset** â€“ Lendingâ€¯Club *accepted* loansÂ 2007â€¯â€“â€¯2018â€¯Q4 (`accepted_2007_to_2018Q4.csv.gz`) â†’â€¯1â€¯345â€¯310 rows after cleaning.  
* **Data processing**  
  1. **prepare_data.py** â€“ loads the rawÂ *.gz, cleans & inserts into `curated.loans_clean`.  
  2. **features.py** â€“ engineersÂ 85 features (financial ratios, temporal lags, oneâ€‘hot grades, FICO ranges) and exports `data/featured/loans_featured.parquet`.  
* **Modeling**  
  * Six LightGBM models (gbdtÂ /Â dartÂ /Â goss Ã—Â baseline & Optunaâ€‘tuned).  
  * Outâ€‘ofâ€‘time splitsÂ : trainâ€¯â‰¤â€¯2016, validationÂ 2017, testÂ 2018.  
  * Metrics logged in MLflowÂ ; best model â‰ˆÂ AUCâ€‘ROCâ€¯0.72, KSâ€¯0.46.  
* **Dashboard**  
  * Leaderboard ranks models by weighted score (AUCâ€‘ROCÂ 0.35, KSÂ 0.25, AUCâ€‘PRÂ 0.20, F1Â 0.10, BrierÂ 0.05, Latency/SizeÂ 0.05).  
  * Tabs show ROC/PR curves, learning curve, and confusion matrix.
